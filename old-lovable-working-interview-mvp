Interview Flow Overview
The application offers multiple types of interviews:

Standard AI Interview - Uses OpenAI's API for text-based interactions
Realtime AI Interview - Uses OpenAI's Realtime API for voice interactions
Token-based Invitation Interviews - Allows candidates to participate via invitation links
Let's go through each component of the interview flow:

1. Interview Session Management
The core of the interview functionality revolves around the interview_sessions table, which records:

Session metadata (candidate and position IDs, timestamps)
Audio recording information
Status tracking
The flow begins when:

A recruiter initiates an interview for a candidate/position
The system creates an interview_sessions record
Realtime connection is established with OpenAI via edge functions
Transcript is recorded during the interview
Results are saved to interview_results table
2. Key Components and Dependencies
Frontend Components
InterviewForm.tsx - Manages candidate selection and interview initialization
RealtimeInterview.tsx - Main interview interface for voice-based interviews
RealtimeAIInterview.tsx - Specialized component for AI-conducted interviews
TranscriptRecorder.tsx - Records and saves interview transcripts
LiveTranscript.tsx - Displays real-time transcript during interviews
Core Hooks
useWebRTC.ts - Manages WebRTC connection for voice interviews
useTranscriptCollection.ts - Coordinates transcript recording, saving, and retrieval
useTranscriptSave.ts - Handles saving transcript data to database
useWebRTCAudio.ts - Manages audio recording and processing
useWebRTCEvents.ts - Handles WebRTC events and messages
useTranscriptEntry.ts - Manages individual transcript entries
3. Edge Functions
realtime-interview
This edge function serves as a secure relay between the frontend and OpenAI's Realtime API:

Receives WebRTC SDP offers from the client
Securely forwards them to OpenAI with API key
Returns SDP answers to establish direct connection
Handles authentication verification

// Key functionality
const response = await fetch('https://api.openai.com/v1/realtime?model=gpt-4o-realtime-preview-2024-12-17', {
  method: 'POST',
  headers: {
    'Authorization': `Bearer ${OPENAI_API_KEY}`,
    'Content-Type': 'application/sdp'
  },
  body: await req.text()
});
realtime-session
Creates a session with OpenAI's Realtime API:

Generates ephemeral tokens for secure connection
Sets up the initial session configuration
Returns client credentials to frontend
generate-interview-summary
Analyzes completed interview transcripts:

Processes transcript and session data
Sends to OpenAI for analysis
Stores the generated summary in interview_results
generate-candidate-assessment
Creates competency-based assessments:

Analyzes transcript against position competencies
Generates numerical scores and justifications
Saves assessment data to candidate_assessments table
update_invitation_status
Updates the status of interview invitations:

Changes status between 'pending', 'in_progress', 'completed'
Records usage timestamps
4. Data Flow and Storage
Database Tables
interview_sessions: Core session information
interview_results: Interview transcripts and evaluations
transcript_entries: Individual transcript entries
interview_invitations: Invitation links for candidates
candidate_assessments: Competency-based evaluations
Types and Interfaces

export interface TranscriptEntry {
  timestamp: string;
  speaker: 'candidate' | 'ai';
  text: string;
  confidence?: number;
  metadata?: {
    audioStartTime?: number;
    audioEndTime?: number;
    type: 'speech' | 'text';
  };
}

export interface InterviewTranscript {
  entries: TranscriptEntry[];
  metadata: {
    startTime: string;
    endTime?: string;
    totalDuration?: number;
    candidateId: string;
    positionId: string;
    sessionId: string;
  };
}
5. Audio Recording and Processing
The system includes sophisticated audio handling:

Records user audio via WebRTC
Uploads recordings to Supabase storage
Links recordings to interview sessions
Determines file extension based on MIME type

export const uploadAudioRecording = async (
  blob: Blob, 
  sessionId: string,
  candidateId: string
): Promise<{ path: string; url: string } | null> => {
  // Creates filename with session ID and timestamp
  // Uploads to 'interview-recordings' bucket
  // Updates interview_sessions table with reference
}
6. Full Interview Flow
Interview Initialization

User selects candidate and position
System creates session record in interview_sessions
For realtime interviews, WebRTC connection established
Position and candidate data fetched to generate context
During Interview

Audio/text exchanged through WebRTC connection
Transcript entries recorded in real-time
Periodic saving of transcript to interview_results
Audio recording saved to storage (for audio interviews)
Interview Completion

Final transcript saved with 'completed' flag
Session status updated to 'completed'
Audio recording finalized and linked
For invitation interviews, invitation status updated
Post-Interview Processing

Summary generation through generate-interview-summary
Competency assessment through generate-candidate-assessment
Results displayed on transcript review page
7. Invitation-based Interviews
The system supports sending interview invitations:

Creates secure tokens in interview_invitations table
Links to specific candidate and position
Sets expiration time for security
Tracks usage state (pending/in_progress/completed)
When used, creates and links interview session
8. Technical Dependencies
WebRTC: For real-time audio communication
Supabase: Database, storage, and edge functions
OpenAI API:
Standard API for text processing
Realtime API for voice interviews
GPT models for transcript analysis
Browser APIs:
MediaRecorder for audio capture
AudioContext for audio processing
WebSocket for realtime communication
9. Security Considerations
Edge functions secure API keys
Session validation through authentication headers
Invitation tokens with expiration
Storage permissions for recordings
Proper CORS headers for API security